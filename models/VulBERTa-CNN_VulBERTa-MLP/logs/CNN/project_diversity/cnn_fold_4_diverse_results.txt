+ val=fold_4_
+ python Finetuning+evaluation_VulBERTa-CNN_diverse.py --seed_input=10102 --data_folder=fold_4_ --train_test=train --batch=3 --epochs=10 --dataset=combined --generate_json=False
Device:  cuda
MultiGPU:  False
data/finetune/combined/fold_4_diverse/train.jsonl
data/finetune/combined/fold_4_diverse/valid.jsonl
data/finetune/combined/fold_4_diverse/test.jsonl
data/finetune/combined/fold_4_holdout/test.jsonl
Traceback (most recent call last):
  File "Finetuning+evaluation_VulBERTa-CNN_diverse.py", line 498, in <module>
    m3.func = m3.func.apply(cleaner)
  File "/home/<ANONYMOUS>/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/core/generic.py", line 5487, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'DataFrame' object has no attribute 'func'
+ val=fold_3_
+ python Finetuning+evaluation_VulBERTa-CNN_diverse.py --seed_input=10102 --data_folder=fold_3_ --train_test=train --batch=16 --epochs=10 --dataset=combined --generate_json=False
Some weights of RobertaModel were not initialized from the model checkpoint at models/pre_trained/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device:  cuda
MultiGPU:  False
data/finetune/combined/fold_3_diverse/train.jsonl
data/finetune/combined/fold_3_diverse/valid.jsonl

myCNN(
  (embed): Embedding(50000, 768, padding_idx=1)
  (conv1): Conv1d(768, 200, kernel_size=(3,), stride=(1,))
  (conv2): Conv1d(768, 200, kernel_size=(4,), stride=(1,))
  (conv3): Conv1d(768, 200, kernel_size=(5,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc1): Linear(in_features=600, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=2, bias=True)
)
Num of trainable param:  2030810
Training started.....
Epoch 1 - Training acc: 0.9982 -Training loss: 0.0154 - Val acc: 0.0618 - Val loss: 33.4592 - Time: 113.8763s 
Epoch 2 - Training acc: 0.9924 -Training loss: 0.1003 - Val acc: 0.0618 - Val loss: 13.3346 - Time: 113.9448s 
Epoch 3 - Training acc: 0.9892 -Training loss: 0.0919 - Val acc: 0.0618 - Val loss: 20.0725 - Time: 113.6933s 
Epoch 4 - Training acc: 0.9923 -Training loss: 0.0811 - Val acc: 0.0618 - Val loss: 16.9761 - Time: 114.0370s 
Epoch 5 - Training acc: 0.9880 -Training loss: 0.1108 - Val acc: 0.0618 - Val loss: 15.7912 - Time: 114.0253s 
Epoch 6 - Training acc: 0.9883 -Training loss: 0.0928 - Val acc: 0.0618 - Val loss: 16.3792 - Time: 113.9527s 
Epoch 7 - Training acc: 0.9879 -Training loss: 0.1125 - Val acc: 0.0618 - Val loss: 11.3891 - Time: 115.7411s 
Epoch 8 - Training acc: 0.9820 -Training loss: 0.1332 - Val acc: 0.0618 - Val loss: 14.9164 - Time: 115.2974s 
Epoch 9 - Training acc: 0.9881 -Training loss: 0.1120 - Val acc: 0.0618 - Val loss: 19.4360 - Time: 116.3341s 
Epoch 10 - Training acc: 0.9884 -Training loss: 0.1453 - Val acc: 0.0618 - Val loss: 12.7259 - Time: 115.0265s 
Training completed!
+ val=fold_4_
+ python Finetuning+evaluation_VulBERTa-CNN_diverse.py --seed_input=10102 --data_folder=fold_4_ --train_test=train --batch=16 --epochs=10 --dataset=combined --generate_json=False
Some weights of RobertaModel were not initialized from the model checkpoint at models/pre_trained/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device:  cuda
MultiGPU:  False
data/finetune/combined/fold_4_diverse/train.jsonl
data/finetune/combined/fold_4_diverse/valid.jsonl

myCNN(
  (embed): Embedding(50000, 768, padding_idx=1)
  (conv1): Conv1d(768, 200, kernel_size=(3,), stride=(1,))
  (conv2): Conv1d(768, 200, kernel_size=(4,), stride=(1,))
  (conv3): Conv1d(768, 200, kernel_size=(5,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
  (fc1): Linear(in_features=600, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=2, bias=True)
)
Num of trainable param:  2030810
Training started.....
Epoch 1 - Training acc: 0.9981 -Training loss: 0.0152 - Val acc: 0.0612 - Val loss: 29.1085 - Time: 114.2921s 
Epoch 2 - Training acc: 0.9919 -Training loss: 0.0727 - Val acc: 0.0612 - Val loss: 15.5817 - Time: 114.1451s 
Epoch 3 - Training acc: 0.9886 -Training loss: 0.1316 - Val acc: 0.0612 - Val loss: 23.0295 - Time: 115.0445s 
Epoch 4 - Training acc: 0.9872 -Training loss: 0.1068 - Val acc: 0.0612 - Val loss: 20.2236 - Time: 115.2370s 
Epoch 5 - Training acc: 0.9901 -Training loss: 0.1248 - Val acc: 0.0612 - Val loss: 16.9378 - Time: 114.2217s 
Epoch 6 - Training acc: 0.9882 -Training loss: 0.1013 - Val acc: 0.0612 - Val loss: 20.4241 - Time: 114.1280s 
Epoch 7 - Training acc: 0.9916 -Training loss: 0.0873 - Val acc: 0.0612 - Val loss: 21.8067 - Time: 114.1598s 
Epoch 8 - Training acc: 0.9893 -Training loss: 0.1048 - Val acc: 0.0612 - Val loss: 15.7039 - Time: 114.1694s 
Epoch 9 - Training acc: 0.9893 -Training loss: 0.1058 - Val acc: 0.0612 - Val loss: 14.7517 - Time: 116.2034s 
Epoch 10 - Training acc: 0.9876 -Training loss: 0.1015 - Val acc: 0.0612 - Val loss: 23.2767 - Time: 114.8770s 
Training completed!
