
(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM python run.py ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --output_folder_name=fold_0_diverse ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --output_dir=./saved_models ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --model_type=roberta ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --tokenizer_name=microsoft/codebert-base ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --model_name_or_path=microsoft/codebert-base ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --do_train ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --train_data_file=../dataset/fold_0_diverse/train.jsonl ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --eval_data_file=../dataset/fold_0_diverse/valid.jsonl ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --test_data_file=../dataset/fold_0_diverse/test.jsonl ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --epoch 5 ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --block_size 400 ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --train_batch_size 32 ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --eval_batch_size 64 ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --learning_rate 2e-5 ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --max_grad_norm 1.0 ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --evaluate_during_training ^ 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>REM --seed 123456 

(base) C:\Users\<ANONYMOUS>\Documents\CodeXGLUE-main\Code-Code\Defect-detection\code>python run.py 	--output_folder_name=fold_0_diverse 	--output_dir=./saved_models 	--model_type=roberta 	--tokenizer_name=microsoft/codebert-base 	--model_name_or_path=microsoft/codebert-base 	--do_eval 	--do_test 	--train_data_file=../dataset/fold_0_diverse/train.jsonl 	--eval_data_file=../dataset/fold_0_diverse/valid.jsonl 	--test_data_file=../dataset/fold_0_holdout/test.jsonl 	--epoch 5 	--block_size 400 	--train_batch_size 32 	--eval_batch_size 64 	--learning_rate 2e-5 	--max_grad_norm 1.0 	--evaluate_during_training 	--seed 123456 
08/21/2022 16:36:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
08/21/2022 16:36:37 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../dataset/fold_0_diverse/train.jsonl', output_folder_name='fold_0_diverse', output_dir='./saved_models', eval_data_file='../dataset/fold_0_diverse/valid.jsonl', test_data_file='../dataset/fold_0_holdout/test.jsonl', model_type='roberta', model_name_or_path='microsoft/codebert-base', mlm=False, mlm_probability=0.15, config_name='', tokenizer_name='microsoft/codebert-base', cache_dir='', block_size=400, do_train=False, do_eval=True, do_test=True, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=5, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
08/21/2022 16:36:50 - INFO - __main__ -   ***** Running evaluation *****
08/21/2022 16:36:50 - INFO - __main__ -     Num examples = 10000
08/21/2022 16:36:50 - INFO - __main__ -     Batch size = 64
08/21/2022 16:37:57 - INFO - __main__ -   ***** Eval results *****
08/21/2022 16:37:57 - INFO - __main__ -     eval_acc = 0.9393
08/21/2022 16:37:57 - INFO - __main__ -     eval_loss = 0.2036
08/21/2022 16:38:08 - INFO - __main__ -   ***** Running Test *****
08/21/2022 16:38:08 - INFO - __main__ -     Num examples = 10031
08/21/2022 16:38:08 - INFO - __main__ -     Batch size = 64
  0%|          | 0/157 [00:00<?, ?it/s]  1%|          | 1/157 [00:00<01:35,  1.63it/s]  1%|1         | 2/157 [00:00<01:11,  2.16it/s]  2%|1         | 3/157 [00:01<01:03,  2.42it/s]  3%|2         | 4/157 [00:01<00:59,  2.55it/s]  3%|3         | 5/157 [00:02<00:57,  2.64it/s]  4%|3         | 6/157 [00:02<00:55,  2.70it/s]  4%|4         | 7/157 [00:02<00:54,  2.73it/s]  5%|5         | 8/157 [00:03<00:53,  2.76it/s]  6%|5         | 9/157 [00:03<00:53,  2.78it/s]  6%|6         | 10/157 [00:03<00:52,  2.79it/s]  7%|7         | 11/157 [00:04<00:52,  2.79it/s]  8%|7         | 12/157 [00:04<00:51,  2.80it/s]  8%|8         | 13/157 [00:04<00:51,  2.79it/s]  9%|8         | 14/157 [00:05<00:51,  2.79it/s] 10%|9         | 15/157 [00:05<00:51,  2.78it/s] 10%|#         | 16/157 [00:05<00:50,  2.77it/s] 11%|#         | 17/157 [00:06<00:50,  2.77it/s] 11%|#1        | 18/157 [00:06<00:50,  2.78it/s] 12%|#2        | 19/157 [00:07<00:49,  2.79it/s] 13%|#2        | 20/157 [00:07<00:49,  2.79it/s] 13%|#3        | 21/157 [00:07<00:48,  2.79it/s] 14%|#4        | 22/157 [00:08<00:48,  2.79it/s] 15%|#4        | 23/157 [00:08<00:47,  2.79it/s] 15%|#5        | 24/157 [00:08<00:47,  2.80it/s] 16%|#5        | 25/157 [00:09<00:47,  2.80it/s] 17%|#6        | 26/157 [00:09<00:46,  2.81it/s] 17%|#7        | 27/157 [00:09<00:46,  2.81it/s] 18%|#7        | 28/157 [00:10<00:46,  2.80it/s] 18%|#8        | 29/157 [00:10<00:45,  2.80it/s] 19%|#9        | 30/157 [00:10<00:45,  2.81it/s] 20%|#9        | 31/157 [00:11<00:44,  2.81it/s] 20%|##        | 32/157 [00:11<00:44,  2.80it/s] 21%|##1       | 33/157 [00:12<00:44,  2.81it/s] 22%|##1       | 34/157 [00:12<00:43,  2.81it/s] 22%|##2       | 35/157 [00:12<00:43,  2.81it/s] 23%|##2       | 36/157 [00:13<00:43,  2.81it/s] 24%|##3       | 37/157 [00:13<00:42,  2.81it/s] 24%|##4       | 38/157 [00:13<00:42,  2.81it/s] 25%|##4       | 39/157 [00:14<00:41,  2.81it/s] 25%|##5       | 40/157 [00:14<00:41,  2.81it/s] 26%|##6       | 41/157 [00:14<00:41,  2.80it/s] 27%|##6       | 42/157 [00:15<00:41,  2.79it/s] 27%|##7       | 43/157 [00:15<00:40,  2.80it/s] 28%|##8       | 44/157 [00:15<00:40,  2.80it/s] 29%|##8       | 45/157 [00:16<00:39,  2.81it/s] 29%|##9       | 46/157 [00:16<00:39,  2.80it/s] 30%|##9       | 47/157 [00:17<00:39,  2.81it/s] 31%|###       | 48/157 [00:17<00:38,  2.82it/s] 31%|###1      | 49/157 [00:17<00:38,  2.81it/s] 32%|###1      | 50/157 [00:18<00:37,  2.82it/s] 32%|###2      | 51/157 [00:18<00:37,  2.81it/s] 33%|###3      | 52/157 [00:18<00:37,  2.80it/s] 34%|###3      | 53/157 [00:19<00:37,  2.80it/s] 34%|###4      | 54/157 [00:19<00:36,  2.80it/s] 35%|###5      | 55/157 [00:19<00:36,  2.79it/s] 36%|###5      | 56/157 [00:20<00:36,  2.79it/s] 36%|###6      | 57/157 [00:20<00:35,  2.79it/s] 37%|###6      | 58/157 [00:20<00:35,  2.79it/s] 38%|###7      | 59/157 [00:21<00:35,  2.79it/s] 38%|###8      | 60/157 [00:21<00:34,  2.79it/s] 39%|###8      | 61/157 [00:22<00:34,  2.78it/s] 39%|###9      | 62/157 [00:22<00:34,  2.79it/s] 40%|####      | 63/157 [00:22<00:33,  2.79it/s] 41%|####      | 64/157 [00:23<00:33,  2.79it/s] 41%|####1     | 65/157 [00:23<00:32,  2.80it/s] 42%|####2     | 66/157 [00:23<00:32,  2.79it/s] 43%|####2     | 67/157 [00:24<00:32,  2.79it/s] 43%|####3     | 68/157 [00:24<00:31,  2.79it/s] 44%|####3     | 69/157 [00:24<00:31,  2.79it/s] 45%|####4     | 70/157 [00:25<00:31,  2.80it/s] 45%|####5     | 71/157 [00:25<00:30,  2.79it/s] 46%|####5     | 72/157 [00:25<00:30,  2.78it/s] 46%|####6     | 73/157 [00:26<00:30,  2.79it/s] 47%|####7     | 74/157 [00:26<00:29,  2.79it/s] 48%|####7     | 75/157 [00:27<00:29,  2.79it/s] 48%|####8     | 76/157 [00:27<00:29,  2.78it/s] 49%|####9     | 77/157 [00:27<00:28,  2.78it/s] 50%|####9     | 78/157 [00:28<00:28,  2.78it/s] 50%|#####     | 79/157 [00:28<00:28,  2.78it/s] 51%|#####     | 80/157 [00:28<00:27,  2.78it/s] 52%|#####1    | 81/157 [00:29<00:27,  2.78it/s] 52%|#####2    | 82/157 [00:29<00:26,  2.79it/s] 53%|#####2    | 83/157 [00:29<00:26,  2.77it/s] 54%|#####3    | 84/157 [00:30<00:26,  2.78it/s] 54%|#####4    | 85/157 [00:30<00:25,  2.78it/s] 55%|#####4    | 86/157 [00:31<00:25,  2.78it/s] 55%|#####5    | 87/157 [00:31<00:25,  2.78it/s] 56%|#####6    | 88/157 [00:31<00:24,  2.79it/s] 57%|#####6    | 89/157 [00:32<00:24,  2.79it/s] 57%|#####7    | 90/157 [00:32<00:24,  2.79it/s] 58%|#####7    | 91/157 [00:32<00:23,  2.78it/s] 59%|#####8    | 92/157 [00:33<00:23,  2.78it/s] 59%|#####9    | 93/157 [00:33<00:22,  2.78it/s] 60%|#####9    | 94/157 [00:33<00:22,  2.78it/s] 61%|######    | 95/157 [00:34<00:22,  2.78it/s] 61%|######1   | 96/157 [00:34<00:21,  2.78it/s] 62%|######1   | 97/157 [00:34<00:21,  2.78it/s] 62%|######2   | 98/157 [00:35<00:21,  2.78it/s] 63%|######3   | 99/157 [00:35<00:20,  2.79it/s] 64%|######3   | 100/157 [00:36<00:20,  2.78it/s] 64%|######4   | 101/157 [00:36<00:20,  2.78it/s] 65%|######4   | 102/157 [00:36<00:19,  2.79it/s] 66%|######5   | 103/157 [00:37<00:19,  2.79it/s] 66%|######6   | 104/157 [00:37<00:18,  2.79it/s] 67%|######6   | 105/157 [00:37<00:18,  2.79it/s] 68%|######7   | 106/157 [00:38<00:18,  2.79it/s] 68%|######8   | 107/157 [00:38<00:17,  2.78it/s] 69%|######8   | 108/157 [00:38<00:17,  2.77it/s] 69%|######9   | 109/157 [00:39<00:17,  2.78it/s] 70%|#######   | 110/157 [00:39<00:16,  2.78it/s] 71%|#######   | 111/157 [00:39<00:16,  2.78it/s] 71%|#######1  | 112/157 [00:40<00:16,  2.78it/s] 72%|#######1  | 113/157 [00:40<00:15,  2.78it/s] 73%|#######2  | 114/157 [00:41<00:15,  2.78it/s] 73%|#######3  | 115/157 [00:41<00:15,  2.78it/s] 74%|#######3  | 116/157 [00:41<00:14,  2.78it/s] 75%|#######4  | 117/157 [00:42<00:14,  2.77it/s] 75%|#######5  | 118/157 [00:42<00:14,  2.78it/s] 76%|#######5  | 119/157 [00:42<00:13,  2.78it/s] 76%|#######6  | 120/157 [00:43<00:13,  2.78it/s] 77%|#######7  | 121/157 [00:43<00:12,  2.78it/s] 78%|#######7  | 122/157 [00:43<00:12,  2.78it/s] 78%|#######8  | 123/157 [00:44<00:12,  2.78it/s] 79%|#######8  | 124/157 [00:44<00:11,  2.77it/s] 80%|#######9  | 125/157 [00:45<00:11,  2.77it/s] 80%|########  | 126/157 [00:45<00:11,  2.77it/s] 81%|########  | 127/157 [00:45<00:10,  2.77it/s] 82%|########1 | 128/157 [00:46<00:10,  2.77it/s] 82%|########2 | 129/157 [00:46<00:10,  2.76it/s] 83%|########2 | 130/157 [00:46<00:09,  2.77it/s] 83%|########3 | 131/157 [00:47<00:09,  2.76it/s] 84%|########4 | 132/157 [00:47<00:09,  2.76it/s] 85%|########4 | 133/157 [00:47<00:08,  2.77it/s] 85%|########5 | 134/157 [00:48<00:08,  2.76it/s] 86%|########5 | 135/157 [00:48<00:07,  2.76it/s] 87%|########6 | 136/157 [00:49<00:07,  2.76it/s] 87%|########7 | 137/157 [00:49<00:07,  2.77it/s] 88%|########7 | 138/157 [00:49<00:06,  2.76it/s] 89%|########8 | 139/157 [00:50<00:06,  2.76it/s] 89%|########9 | 140/157 [00:50<00:06,  2.77it/s] 90%|########9 | 141/157 [00:50<00:05,  2.77it/s] 90%|######### | 142/157 [00:51<00:05,  2.77it/s] 91%|#########1| 143/157 [00:51<00:05,  2.77it/s] 92%|#########1| 144/157 [00:51<00:04,  2.77it/s] 92%|#########2| 145/157 [00:52<00:04,  2.76it/s] 93%|#########2| 146/157 [00:52<00:03,  2.76it/s] 94%|#########3| 147/157 [00:52<00:03,  2.76it/s] 94%|#########4| 148/157 [00:53<00:03,  2.76it/s] 95%|#########4| 149/157 [00:53<00:02,  2.76it/s] 96%|#########5| 150/157 [00:54<00:02,  2.75it/s] 96%|#########6| 151/157 [00:54<00:02,  2.75it/s] 97%|#########6| 152/157 [00:54<00:01,  2.73it/s] 97%|#########7| 153/157 [00:55<00:01,  2.74it/s] 98%|#########8| 154/157 [00:55<00:01,  2.74it/s] 99%|#########8| 155/157 [00:55<00:00,  2.73it/s] 99%|#########9| 156/157 [00:56<00:00,  2.73it/s]100%|##########| 157/157 [00:56<00:00,  2.97it/s]100%|##########| 157/157 [00:56<00:00,  2.78it/s]

Accuracy: 0.952347722061609
Precision: 0.10256410256410256
F-measure: 0.01646090534979424
Recall: 0.008948545861297539
