08/28/2022 00:08:23 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
08/28/2022 00:08:27 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x2b657880e710>
08/28/2022 00:09:39 - INFO - __main__ -   *** Total Sample ***
08/28/2022 00:09:39 - INFO - __main__ -   	Total: 69122	selected: 69122	percent: 1.0	
08/28/2022 00:09:39 - INFO - __main__ -   *** Sample ***
08/28/2022 00:09:39 - INFO - __main__ -   Total sample
08/28/2022 00:09:39 - INFO - __main__ -   idx: 0
08/28/2022 00:09:39 - INFO - __main__ -   label: 0
08/28/2022 00:09:39 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_av', '_', 'cold', '_int', '_v', 'd', 'ade', 'c', '_', 'init', '(', 'AV', 'Cod', 'ec', 'Context', '_*', 'av', 'ctx', ')', '_{', '_V', 'D', 'AD', 'ec', 'oder', 'Context', '_*', 'ctx', '_=', '_av', 'ctx', '->', 'priv', '_', 'data', ';', '_struct', '_v', 'da', '_', 'context', '_*', 'v', 'da', '_', 'ctx', '_=', '_&', 'ctx', '->', 'v', 'da', '_', 'ctx', ';', '_OS', 'Status', '_status', ';', '_int', '_ret', ';', '_c', 'tx', '->', 'h', '264', '_', 'initialized', '_=', '_0', ';', '_/*', '_init', '_p', 'ix', '_', 'fm', 'ts', '_of', '_codec', '_*/', '_if', '_(!', 'ff', '_', 'h', '264', '_', 'v', 'da', '_', 'dec', 'oder', '.', 'p', 'ix', '_', 'fm', 'ts', ')', '_{', '_if', '_(', 'k', 'C', 'FC', 'ore', 'Found', 'ation', 'Version', 'Number', '_<', '_k', 'C', 'FC', 'ore', 'Found', 'ation', 'Version', 'Number', '10', '_', '7', ')', '_ff', '_', 'h', '264', '_', 'v', 'da', '_', 'dec', 'oder', '.', 'p', 'ix', '_', 'fm', 'ts', '_=', '_v', 'da', '_', 'p', 'ix', 'fm', 'ts', '_', 'pri', 'or', '_', '10', '_', '7', ';', '_else', '_ff', '_', 'h', '264', '_', 'v', 'da', '_', 'dec', 'oder', '.', 'p', 'ix', '_', 'fm', 'ts', '_=', '_v', 'da', '_', 'p', 'ix', 'fm', 'ts', ';', '_}', '_/*', '_init', '_v', 'da', '_*/', '_mem', 'set', '(', 'v', 'da', '_', 'ctx', ',', '_0', ',', '_sizeof', '(', 'struct', '_v', 'da', '_', 'context', '));', '_v', 'da', '_', 'ctx', '->', 'width', '_=', '_av', 'ctx', '->', 'width', ';', '_v', 'da', '_', 'ctx', '->', 'height', '_=', '_av', 'ctx', '->', 'height', ';', '_v', 'da', '_', 'ctx', '->', 'format', '_=', "_'", 'av', 'c', '1', "';", '_v', 'da', '_', 'ctx', '->', 'use', '_', 'sync', '_', 'dec', 'oding', '_=', '_1', ';', '_v', 'da', '_', 'ctx', '->', 'use', '_', 'ref', '_', 'buffer', '_=', '_1', ';', '_c', 'tx', '->', 'p', 'ix', '_', 'f', 'mt', '_=', '_av', 'ctx', '->', 'get', '_', 'format', '(', 'av', 'ctx', ',', '_av', 'ctx', '->', 'cod', 'ec', '->', 'p', 'ix', '_', 'fm', 'ts', ');', '_switch', '_(', 'ctx', '->', 'p', 'ix', '_', 'f', 'mt', ')', '_{', '_case', '_AV', '_', 'P', 'IX', '_', 'F', 'MT', '_', 'U', 'Y', 'V', 'Y', '422', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'p', 'ix', '_', 'f', 'mt', '_', 'type', '_=', "_'", '2', 'v', 'uy', "';", '_break', ';', '_case', '_AV', '_', 'P', 'IX', '_', 'F', 'MT', '_', 'Y', 'U', 'Y', 'V', '422', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'p', 'ix', '_', 'f', 'mt', '_', 'type', '_=', "_'", 'yu', 'vs', "';", '_break', ';', '_case', '_AV', '_', 'P', 'IX', '_', 'F', 'MT', '_', 'NV', '12', ':', '</s>']
08/28/2022 00:09:39 - INFO - __main__ -   input_ids: 0 42653 6402 1215 33912 6979 748 417 1829 438 1215 25153 1640 10612 47436 3204 48522 1009 1469 49575 43 25522 468 495 2606 3204 15362 48522 1009 49575 5457 6402 49575 46613 25943 1215 23687 131 29916 748 6106 1215 46796 1009 705 6106 1215 49575 5457 359 49575 46613 705 6106 1215 49575 131 8192 47731 2194 131 6979 5494 131 740 43820 46613 298 29137 1215 49722 5457 321 131 48565 45511 181 3181 1215 40523 1872 9 45797 48404 114 48209 3145 1215 298 29137 1215 705 6106 1215 11127 15362 4 642 3181 1215 40523 1872 43 25522 114 36 330 347 5268 1688 29991 1258 47322 43623 28696 449 347 5268 1688 29991 1258 47322 43623 698 1215 406 43 48400 1215 298 29137 1215 705 6106 1215 11127 15362 4 642 3181 1215 40523 1872 5457 748 6106 1215 642 3181 40523 1872 1215 13718 368 1215 698 1215 406 131 1493 48400 1215 298 29137 1215 705 6106 1215 11127 15362 4 642 3181 1215 40523 1872 5457 748 6106 1215 642 3181 40523 1872 131 35524 48565 45511 748 6106 48404 26012 8738 1640 705 6106 1215 49575 6 321 6 49907 1640 25384 748 6106 1215 46796 48749 748 6106 1215 49575 46613 36097 5457 6402 49575 46613 36097 131 748 6106 1215 49575 46613 37009 5457 6402 49575 46613 37009 131 748 6106 1215 49575 46613 34609 5457 128 1469 438 134 23500 748 6106 1215 49575 46613 3698 1215 45176 1215 11127 19519 5457 112 131 748 6106 1215 49575 46613 3698 1215 13043 1215 47438 5457 112 131 740 43820 46613 642 3181 1215 506 16100 5457 6402 49575 46613 6460 1215 34609 1640 1469 49575 6 6402 49575 46613 29659 3204 46613 642 3181 1215 40523 1872 4397 5405 36 49575 46613 642 3181 1215 506 16100 43 25522 403 17307 1215 510 9482 1215 597 11674 1215 791 975 846 975 37319 35 748 6106 1215 49575 46613 38635 1215 642 3181 1215 506 16100 1215 12528 5457 128 176 705 5781 23500 1108 131 403 17307 1215 510 9482 1215 597 11674 1215 975 791 975 846 37319 35 748 6106 1215 49575 46613 38635 1215 642 3181 1215 506 16100 1215 12528 5457 128 29159 15597 23500 1108 131 403 17307 1215 510 9482 1215 597 11674 1215 31668 1092 35 2
08/28/2022 00:09:39 - INFO - __main__ -   *** Sample ***
08/28/2022 00:09:39 - INFO - __main__ -   Total sample
08/28/2022 00:09:39 - INFO - __main__ -   idx: 1
08/28/2022 00:09:39 - INFO - __main__ -   label: 1
08/28/2022 00:09:39 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_int', '_d', 'ds', '_', 'dec', 'ode', '(', 'AV', 'Cod', 'ec', 'Context', '_*', 'av', 'ctx', ',', '_void', '_*', 'data', ',', '_int', '_*', 'got', '_', 'frame', ',', '_A', 'VP', 'acket', '_*', 'av', 'p', 'kt', ')', '_{', '_D', 'DS', 'Context', '_*', 'ctx', '_=', '_av', 'ctx', '->', 'priv', '_', 'data', ';', '_Get', 'Byte', 'Context', '_*', 'g', 'bc', '_=', '_&', 'ctx', '->', 'g', 'bc', ';', '_AV', 'Frame', '_*', 'frame', '_=', '_data', ';', '_int', '_m', 'ip', 'map', ';', '_int', '_ret', ';', '_ff', '_', 'text', 'ured', 'sp', '_', 'init', '(&', 'ctx', '->', 'tex', 'd', 'sp', ');', '_by', 'test', 'ream', '2', '_', 'init', '(', 'g', 'bc', ',', '_av', 'p', 'kt', '->', 'data', ',', '_av', 'p', 'kt', '->', 'size', ');', '_if', '_(', 'by', 'test', 'ream', '2', '_', 'get', '_', 'bytes', '_', 'left', '(', 'g', 'bc', ')', '_<', '_128', ')', '_{', '_av', '_', 'log', '(', 'av', 'ctx', ',', '_AV', '_', 'LOG', '_', 'ERROR', ',', '_"', 'Frame', '_is', '_too', '_small', '_(%', 'd', ').', '\\', 'n', '",', '_by', 'test', 'ream', '2', '_', 'get', '_', 'bytes', '_', 'left', '(', 'g', 'bc', '));', '_return', '_A', 'VER', 'ROR', '_', 'IN', 'VAL', 'ID', 'DATA', ';', '_}', '_if', '_(', 'by', 'test', 'ream', '2', '_', 'get', '_', 'le', '32', '(', 'g', 'bc', ')', '_!=', '_MK', 'TAG', "('", 'D', "',", "_'", 'D', "',", "_'", 'S', "',", "_'", "_'", ')', '_||', '_by', 'test', 'ream', '2', '_', 'get', '_', 'le', '32', '(', 'g', 'bc', ')', '_!=', '_124', ')', '_{', '_//', '_header', '_size', '_av', '_', 'log', '(', 'av', 'ctx', ',', '_AV', '_', 'LOG', '_', 'ERROR', ',', '_"', 'Invalid', '_D', 'DS', '_header', '.', '\\', 'n', '");', '_return', '_A', 'VER', 'ROR', '_', 'IN', 'VAL', 'ID', 'DATA', ';', '_}', '_by', 'test', 'ream', '2', '_', 'skip', '(', 'g', 'bc', ',', '_4', ');', '_//', '_flags', '_av', 'ctx', '->', 'height', '_=', '_by', 'test', 'ream', '2', '_', 'get', '_', 'le', '32', '(', 'g', 'bc', ');', '_av', 'ctx', '->', 'width', '_=', '_by', 'test', 'ream', '2', '_', 'get', '_', 'le', '32', '(', 'g', 'bc', ');', '_ret', '_=', '_av', '_', 'image', '_', 'check', '_', 'size', '(', 'av', 'ctx', '->', 'width', ',', '_av', 'ctx', '->', 'height', ',', '_0', ',', '_av', 'ctx', ');', '_if', '_(', 'ret', '_<', '_0', ')', '_{', '_av', '_', 'log', '(', 'av', 'ctx', ',', '_AV', '_', 'LOG', '_', 'ERROR', ',', '_"', 'Invalid', '_image', '_size', '_%', 'dx', '%', 'd', '.', '\\', 'n', '",', '_av', 'ctx', '->', 'width', ',', '_av', 'ctx', '->', 'height', ');', '_return', '_ret', ';', '_}', '_/*', '_Since', '_codec', '_is', '_based', '_on', '_4', 'x', '4', '_blocks', ',', '_size', '</s>']
08/28/2022 00:09:39 - INFO - __main__ -   input_ids: 0 42653 6979 385 11622 1215 11127 4636 1640 10612 47436 3204 48522 1009 1469 49575 6 13842 1009 23687 6 6979 1009 22371 1215 26061 6 83 12015 32561 1009 1469 642 7282 43 25522 211 5433 48522 1009 49575 5457 6402 49575 46613 25943 1215 23687 131 2315 47447 48522 1009 571 23219 5457 359 49575 46613 571 23219 131 17307 46766 1009 26061 5457 414 131 6979 475 1588 32557 131 6979 5494 131 48400 1215 29015 4075 4182 1215 25153 49763 49575 46613 25401 417 4182 4397 30 21959 26930 176 1215 25153 1640 571 23219 6 6402 642 7282 46613 23687 6 6402 642 7282 46613 10799 4397 114 36 1409 21959 26930 176 1215 6460 1215 46823 1215 6960 1640 571 23219 43 28696 13950 43 25522 6402 1215 12376 1640 1469 49575 6 17307 1215 45403 1215 46734 6 22 46766 16 350 650 48086 417 322 37457 282 1297 30 21959 26930 176 1215 6460 1215 46823 1215 6960 1640 571 23219 48749 671 83 9847 45055 1215 2444 39766 2688 48242 131 35524 114 36 1409 21959 26930 176 1215 6460 1215 459 2881 1640 571 23219 43 49333 20149 46985 45803 495 3934 128 495 3934 128 104 3934 128 128 43 45056 30 21959 26930 176 1215 6460 1215 459 2881 1640 571 23219 43 49333 19446 43 25522 21277 12734 1836 6402 1215 12376 1640 1469 49575 6 17307 1215 45403 1215 46734 6 22 49695 211 5433 12734 4 37457 282 45751 671 83 9847 45055 1215 2444 39766 2688 48242 131 35524 30 21959 26930 176 1215 46554 1640 571 23219 6 204 4397 21277 9287 6402 49575 46613 37009 5457 30 21959 26930 176 1215 6460 1215 459 2881 1640 571 23219 4397 6402 49575 46613 36097 5457 30 21959 26930 176 1215 6460 1215 459 2881 1640 571 23219 4397 5494 5457 6402 1215 20094 1215 15954 1215 10799 1640 1469 49575 46613 36097 6 6402 49575 46613 37009 6 321 6 6402 49575 4397 114 36 4903 28696 321 43 25522 6402 1215 12376 1640 1469 49575 6 17307 1215 45403 1215 46734 6 22 49695 2274 1836 7606 46106 207 417 4 37457 282 1297 6402 49575 46613 36097 6 6402 49575 46613 37009 4397 671 5494 131 35524 48565 1773 45797 16 716 15 204 1178 306 5491 6 1836 2
08/28/2022 00:09:39 - INFO - __main__ -   *** Sample ***
08/28/2022 00:09:39 - INFO - __main__ -   Total sample
08/28/2022 00:09:39 - INFO - __main__ -   idx: 2
08/28/2022 00:09:39 - INFO - __main__ -   label: 1
08/28/2022 00:09:39 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_void', '_check', '_', 'low', 'pass', '_', 'line', '(', 'int', '_depth', '){', '_LOC', 'AL', '_', 'AL', 'IGN', 'ED', '_', '32', '(', 'uint', '8', '_', 't', ',', '_src', ',', '_[', 'S', 'RC', '_', 'SIZE', ']);', '_LOC', 'AL', '_', 'AL', 'IGN', 'ED', '_', '32', '(', 'uint', '8', '_', 't', ',', '_dst', '_', 'ref', ',', '_[', 'W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', ']);', '_LOC', 'AL', '_', 'AL', 'IGN', 'ED', '_', '32', '(', 'uint', '8', '_', 't', ',', '_dst', '_', 'new', ',', '_[', 'W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', ']);', '_int', '_w', '_=', '_W', 'ID', 'TH', ';', '_int', '_m', 'ref', '_=', '_W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', '_*', '_-', '1', ';', '_int', '_pref', '_=', '_W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', ';', '_int', '_i', ',', '_depth', '_', 'byte', ';', '_Inter', 'lace', 'Context', '_s', ';', '_declare', '_', 'func', '(', 'void', ',', '_uint', '8', '_', 't', '_*', 'd', 'st', 'p', ',', '_ptr', 'diff', '_', 't', '_lines', 'ize', ',', '_const', '_uint', '8', '_', 't', '_*', 'src', 'p', ',', '_ptr', 'diff', '_', 't', '_m', 'ref', ',', '_ptr', 'diff', '_', 't', '_pref', ',', '_int', '_clip', '_', 'max', ');', '_s', '.', 'low', 'pass', '_=', '_1', ';', '_s', '.', 'low', 'pass', '_=', '_V', 'LP', 'F', '_', 'LIN', ';', '_depth', '_', 'byte', '_=', '_depth', '_>>', '_3', ';', '_w', '_/', '=', '_depth', '_', 'byte', ';', '_mem', 'set', '(', 'src', ',', '_0', ',', '_S', 'RC', '_', 'SIZE', ');', '_mem', 'set', '(', 'd', 'st', '_', 'ref', ',', '_0', ',', '_W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', ');', '_mem', 'set', '(', 'd', 'st', '_', 'new', ',', '_0', ',', '_W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', ');', '_random', 'ize', '_', 'buff', 'ers', '(', 'src', ',', '_S', 'RC', '_', 'SIZE', ');', '_ff', '_', 'inter', 'lace', '_', 'init', '(&', 's', ',', '_depth', ');', '_if', '_(', 'check', '_', 'func', '(', 's', '.', 'low', 'pass', '_', 'line', ',', '_"', 'low', 'pass', '_', 'line', '_', '%', 'd', '",', '_depth', '))', '_{', '_for', '_(', 'i', '_=', '_0', ';', '_i', '_<', '_32', ';', '_i', '++)', '_{', '_/*', '_simulate', '_crop', '_*/', '_call', '_', 'ref', '(', 'd', 'st', '_', 'ref', ',', '_w', ',', '_src', '_+', '_W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', ',', '_m', 'ref', '_-', '_i', '*', 'depth', '_', 'byte', ',', '_pref', ',', '_0', ');', '_call', '_', 'new', '(', 'd', 'st', '_', 'new', ',', '_w', ',', '_src', '_+', '_W', 'ID', 'TH', '_', 'P', 'ADD', 'ED', ',', '_m', 'ref', '_-', '_i', '*', 'depth', '_', 'byte', ',', '_pref', ',', '_0', ');', '_if', '</s>']
08/28/2022 00:09:39 - INFO - __main__ -   input_ids: 0 42653 13842 1649 1215 5481 10212 1215 1902 1640 2544 5581 48512 27560 2118 1215 2118 30596 1691 1215 2881 1640 47157 398 1215 90 6 47215 6 646 104 5199 1215 49340 48601 27560 2118 1215 2118 30596 1691 1215 2881 1640 47157 398 1215 90 6 49339 1215 13043 6 646 771 2688 3732 1215 510 37705 1691 48601 27560 2118 1215 2118 30596 1691 1215 2881 1640 47157 398 1215 90 6 49339 1215 4651 6 646 771 2688 3732 1215 510 37705 1691 48601 6979 885 5457 305 2688 3732 131 6979 475 13043 5457 305 2688 3732 1215 510 37705 1691 1009 111 134 131 6979 33284 5457 305 2688 3732 1215 510 37705 1691 131 6979 939 6 5581 1215 47692 131 3870 44603 48522 579 131 10152 1215 48901 1640 47908 6 49315 398 1215 90 1009 417 620 642 6 49892 32278 1215 90 2301 2072 6 10759 49315 398 1215 90 1009 45692 642 6 49892 32278 1215 90 475 13043 6 49892 32278 1215 90 33284 6 6979 7200 1215 29459 4397 579 4 5481 10212 5457 112 131 579 4 5481 10212 5457 468 21992 597 1215 13748 131 5581 1215 47692 5457 5581 8488 155 131 885 1589 5214 5581 1215 47692 131 26012 8738 1640 45692 6 321 6 208 5199 1215 49340 4397 26012 8738 1640 417 620 1215 13043 6 321 6 305 2688 3732 1215 510 37705 1691 4397 26012 8738 1640 417 620 1215 4651 6 321 6 305 2688 3732 1215 510 37705 1691 4397 9624 2072 1215 43637 268 1640 45692 6 208 5199 1215 49340 4397 48400 1215 8007 44603 1215 25153 49763 29 6 5581 4397 114 36 15954 1215 48901 1640 29 4 5481 10212 1215 1902 6 22 5481 10212 1215 1902 1215 207 417 1297 5581 35122 25522 13 36 118 5457 321 131 939 28696 2107 131 939 49346 25522 48565 34233 6792 48404 486 1215 13043 1640 417 620 1215 13043 6 885 6 47215 2055 305 2688 3732 1215 510 37705 1691 6 475 13043 111 939 3226 11583 1215 47692 6 33284 6 321 4397 486 1215 4651 1640 417 620 1215 4651 6 885 6 47215 2055 305 2688 3732 1215 510 37705 1691 6 475 13043 111 939 3226 11583 1215 47692 6 33284 6 321 4397 114 2
08/28/2022 00:09:39 - INFO - __main__ -   ***** Running training *****
08/28/2022 00:09:39 - INFO - __main__ -     Num examples = 69122
08/28/2022 00:09:39 - INFO - __main__ -     Num Epochs = 30
08/28/2022 00:09:39 - INFO - __main__ -     Instantaneous batch size per GPU = 512
08/28/2022 00:09:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 512
08/28/2022 00:09:39 - INFO - __main__ -     Gradient Accumulation steps = 1
08/28/2022 00:09:39 - INFO - __main__ -     Total optimization steps = 4080
08/28/2022 00:18:59 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 00:18:59 - INFO - __main__ -     Num examples = 8592
08/28/2022 00:18:59 - INFO - __main__ -     Batch size = 128
08/28/2022 00:19:46 - INFO - __main__ -     eval_loss = 0.3466
08/28/2022 00:19:46 - INFO - __main__ -     eval_acc = 0.8934
08/28/2022 00:19:46 - INFO - __main__ -     ********************
08/28/2022 00:19:46 - INFO - __main__ -     Best acc:0.8934
08/28/2022 00:19:46 - INFO - __main__ -     ********************
08/28/2022 00:19:46 - INFO - __main__ -   Saving model checkpoint to <ANONYMOUS>/<ANONYMOUS>/saved_models/regvd/RQB1/imbalanced_0.4/checkpoint-best-acc/model.bin
08/28/2022 00:19:46 - INFO - __main__ -   epoch 0 loss 0.47003
08/28/2022 00:29:09 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 00:29:09 - INFO - __main__ -     Num examples = 8592
08/28/2022 00:29:09 - INFO - __main__ -     Batch size = 128
08/28/2022 00:29:59 - INFO - __main__ -     eval_loss = 0.3373
08/28/2022 00:29:59 - INFO - __main__ -     eval_acc = 0.8935
08/28/2022 00:29:59 - INFO - __main__ -     ********************
08/28/2022 00:29:59 - INFO - __main__ -     Best acc:0.8935
08/28/2022 00:29:59 - INFO - __main__ -     ********************
08/28/2022 00:30:00 - INFO - __main__ -   Saving model checkpoint to <ANONYMOUS>/<ANONYMOUS>/saved_models/regvd/RQB1/imbalanced_0.4/checkpoint-best-acc/model.bin
08/28/2022 00:30:00 - INFO - __main__ -   epoch 1 loss 0.31157
08/28/2022 00:39:30 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 00:39:30 - INFO - __main__ -     Num examples = 8592
08/28/2022 00:39:30 - INFO - __main__ -     Batch size = 128
08/28/2022 00:40:21 - INFO - __main__ -     eval_loss = 0.4209
08/28/2022 00:40:21 - INFO - __main__ -     eval_acc = 0.8934
08/28/2022 00:40:21 - INFO - __main__ -   epoch 2 loss 0.29302
08/28/2022 00:50:00 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 00:50:00 - INFO - __main__ -     Num examples = 8592
08/28/2022 00:50:00 - INFO - __main__ -     Batch size = 128
08/28/2022 00:50:50 - INFO - __main__ -     eval_loss = 0.2987
08/28/2022 00:50:50 - INFO - __main__ -     eval_acc = 0.893
08/28/2022 00:50:51 - INFO - __main__ -   epoch 3 loss 0.29134
08/28/2022 01:00:08 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 01:00:08 - INFO - __main__ -     Num examples = 8592
08/28/2022 01:00:08 - INFO - __main__ -     Batch size = 128
08/28/2022 01:00:57 - INFO - __main__ -     eval_loss = 0.2969
08/28/2022 01:00:57 - INFO - __main__ -     eval_acc = 0.8929
08/28/2022 01:00:57 - INFO - __main__ -   epoch 4 loss 0.28082
08/28/2022 01:10:00 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 01:10:00 - INFO - __main__ -     Num examples = 8592
08/28/2022 01:10:00 - INFO - __main__ -     Batch size = 128
08/28/2022 01:10:46 - INFO - __main__ -     eval_loss = 0.2911
08/28/2022 01:10:46 - INFO - __main__ -     eval_acc = 0.8909
08/28/2022 01:10:46 - INFO - __main__ -   epoch 5 loss 0.27442
08/28/2022 01:19:45 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 01:19:45 - INFO - __main__ -     Num examples = 8592
08/28/2022 01:19:45 - INFO - __main__ -     Batch size = 128
08/28/2022 01:20:31 - INFO - __main__ -     eval_loss = 0.2892
08/28/2022 01:20:31 - INFO - __main__ -     eval_acc = 0.8915
08/28/2022 01:20:31 - INFO - __main__ -   epoch 6 loss 0.27012
08/28/2022 01:30:06 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 01:30:06 - INFO - __main__ -     Num examples = 8592
08/28/2022 01:30:06 - INFO - __main__ -     Batch size = 128
08/28/2022 01:30:56 - INFO - __main__ -     eval_loss = 0.2929
08/28/2022 01:30:56 - INFO - __main__ -     eval_acc = 0.8929
08/28/2022 01:30:56 - INFO - __main__ -   epoch 7 loss 0.26859
08/28/2022 01:40:22 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 01:40:22 - INFO - __main__ -     Num examples = 8592
08/28/2022 01:40:22 - INFO - __main__ -     Batch size = 128
08/28/2022 01:41:15 - INFO - __main__ -     eval_loss = 0.2861
08/28/2022 01:41:15 - INFO - __main__ -     eval_acc = 0.8941
08/28/2022 01:41:15 - INFO - __main__ -     ********************
08/28/2022 01:41:15 - INFO - __main__ -     Best acc:0.8941
08/28/2022 01:41:15 - INFO - __main__ -     ********************
08/28/2022 01:41:15 - INFO - __main__ -   Saving model checkpoint to <ANONYMOUS>/<ANONYMOUS>/saved_models/regvd/RQB1/imbalanced_0.4/checkpoint-best-acc/model.bin
08/28/2022 01:41:15 - INFO - __main__ -   epoch 8 loss 0.26085
08/28/2022 01:50:32 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 01:50:32 - INFO - __main__ -     Num examples = 8592
08/28/2022 01:50:32 - INFO - __main__ -     Batch size = 128
08/28/2022 01:51:21 - INFO - __main__ -     eval_loss = 0.2828
08/28/2022 01:51:21 - INFO - __main__ -     eval_acc = 0.8941
08/28/2022 01:51:21 - INFO - __main__ -   epoch 9 loss 0.25495
08/28/2022 02:00:39 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 02:00:39 - INFO - __main__ -     Num examples = 8592
08/28/2022 02:00:39 - INFO - __main__ -     Batch size = 128
08/28/2022 02:01:29 - INFO - __main__ -     eval_loss = 0.2801
08/28/2022 02:01:29 - INFO - __main__ -     eval_acc = 0.8911
08/28/2022 02:01:29 - INFO - __main__ -   epoch 10 loss 0.25277
08/28/2022 02:10:55 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 02:10:55 - INFO - __main__ -     Num examples = 8592
08/28/2022 02:10:55 - INFO - __main__ -     Batch size = 128
08/28/2022 02:11:44 - INFO - __main__ -     eval_loss = 0.2751
08/28/2022 02:11:44 - INFO - __main__ -     eval_acc = 0.8908
08/28/2022 02:11:44 - INFO - __main__ -   epoch 11 loss 0.24837
08/28/2022 02:21:21 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 02:21:21 - INFO - __main__ -     Num examples = 8592
08/28/2022 02:21:21 - INFO - __main__ -     Batch size = 128
08/28/2022 02:22:13 - INFO - __main__ -     eval_loss = 0.2783
08/28/2022 02:22:13 - INFO - __main__ -     eval_acc = 0.8935
08/28/2022 02:22:13 - INFO - __main__ -   epoch 12 loss 0.24014
08/28/2022 02:31:34 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 02:31:34 - INFO - __main__ -     Num examples = 8592
08/28/2022 02:31:34 - INFO - __main__ -     Batch size = 128
08/28/2022 02:32:25 - INFO - __main__ -     eval_loss = 0.2864
08/28/2022 02:32:25 - INFO - __main__ -     eval_acc = 0.8951
08/28/2022 02:32:25 - INFO - __main__ -     ********************
08/28/2022 02:32:25 - INFO - __main__ -     Best acc:0.8951
08/28/2022 02:32:25 - INFO - __main__ -     ********************
08/28/2022 02:32:26 - INFO - __main__ -   Saving model checkpoint to <ANONYMOUS>/<ANONYMOUS>/saved_models/regvd/RQB1/imbalanced_0.4/checkpoint-best-acc/model.bin
08/28/2022 02:32:26 - INFO - __main__ -   epoch 13 loss 0.23344
08/28/2022 02:41:48 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 02:41:48 - INFO - __main__ -     Num examples = 8592
08/28/2022 02:41:48 - INFO - __main__ -     Batch size = 128
08/28/2022 02:42:42 - INFO - __main__ -     eval_loss = 0.2781
08/28/2022 02:42:42 - INFO - __main__ -     eval_acc = 0.8921
08/28/2022 02:42:42 - INFO - __main__ -   epoch 14 loss 0.22989
08/28/2022 02:52:15 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 02:52:15 - INFO - __main__ -     Num examples = 8592
08/28/2022 02:52:15 - INFO - __main__ -     Batch size = 128
08/28/2022 02:53:03 - INFO - __main__ -     eval_loss = 0.31
08/28/2022 02:53:03 - INFO - __main__ -     eval_acc = 0.8972
08/28/2022 02:53:03 - INFO - __main__ -     ********************
08/28/2022 02:53:03 - INFO - __main__ -     Best acc:0.8972
08/28/2022 02:53:03 - INFO - __main__ -     ********************
08/28/2022 02:53:04 - INFO - __main__ -   Saving model checkpoint to <ANONYMOUS>/<ANONYMOUS>/saved_models/regvd/RQB1/imbalanced_0.4/checkpoint-best-acc/model.bin
08/28/2022 02:53:04 - INFO - __main__ -   epoch 15 loss 0.22352
08/28/2022 03:02:26 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 03:02:26 - INFO - __main__ -     Num examples = 8592
08/28/2022 03:02:26 - INFO - __main__ -     Batch size = 128
08/28/2022 03:03:14 - INFO - __main__ -     eval_loss = 0.2851
08/28/2022 03:03:14 - INFO - __main__ -     eval_acc = 0.8923
08/28/2022 03:03:15 - INFO - __main__ -   epoch 16 loss 0.21987
08/28/2022 03:12:54 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 03:12:54 - INFO - __main__ -     Num examples = 8592
08/28/2022 03:12:54 - INFO - __main__ -     Batch size = 128
08/28/2022 03:13:40 - INFO - __main__ -     eval_loss = 0.2815
08/28/2022 03:13:40 - INFO - __main__ -     eval_acc = 0.8942
08/28/2022 03:13:40 - INFO - __main__ -   epoch 17 loss 0.21329
08/28/2022 03:22:57 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 03:22:57 - INFO - __main__ -     Num examples = 8592
08/28/2022 03:22:57 - INFO - __main__ -     Batch size = 128
08/28/2022 03:23:49 - INFO - __main__ -     eval_loss = 0.2939
08/28/2022 03:23:49 - INFO - __main__ -     eval_acc = 0.8928
08/28/2022 03:23:49 - INFO - __main__ -   epoch 18 loss 0.20727
08/28/2022 03:33:22 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 03:33:22 - INFO - __main__ -     Num examples = 8592
08/28/2022 03:33:22 - INFO - __main__ -     Batch size = 128
08/28/2022 03:34:10 - INFO - __main__ -     eval_loss = 0.2791
08/28/2022 03:34:10 - INFO - __main__ -     eval_acc = 0.8915
08/28/2022 03:34:11 - INFO - __main__ -   epoch 19 loss 0.20411
08/28/2022 03:43:44 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 03:43:44 - INFO - __main__ -     Num examples = 8592
08/28/2022 03:43:44 - INFO - __main__ -     Batch size = 128
08/28/2022 03:44:33 - INFO - __main__ -     eval_loss = 0.2817
08/28/2022 03:44:33 - INFO - __main__ -     eval_acc = 0.894
08/28/2022 03:44:33 - INFO - __main__ -   epoch 20 loss 0.19824
08/28/2022 03:54:16 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 03:54:16 - INFO - __main__ -     Num examples = 8592
08/28/2022 03:54:16 - INFO - __main__ -     Batch size = 128
08/28/2022 03:55:04 - INFO - __main__ -     eval_loss = 0.2796
08/28/2022 03:55:04 - INFO - __main__ -     eval_acc = 0.893
08/28/2022 03:55:04 - INFO - __main__ -   epoch 21 loss 0.1928
08/28/2022 04:04:46 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 04:04:46 - INFO - __main__ -     Num examples = 8592
08/28/2022 04:04:46 - INFO - __main__ -     Batch size = 128
08/28/2022 04:05:38 - INFO - __main__ -     eval_loss = 0.2975
08/28/2022 04:05:38 - INFO - __main__ -     eval_acc = 0.8977
08/28/2022 04:05:38 - INFO - __main__ -     ********************
08/28/2022 04:05:38 - INFO - __main__ -     Best acc:0.8977
08/28/2022 04:05:38 - INFO - __main__ -     ********************
08/28/2022 04:05:39 - INFO - __main__ -   Saving model checkpoint to <ANONYMOUS>/<ANONYMOUS>/saved_models/regvd/RQB1/imbalanced_0.4/checkpoint-best-acc/model.bin
08/28/2022 04:05:39 - INFO - __main__ -   epoch 22 loss 0.18954
08/28/2022 04:15:16 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 04:15:16 - INFO - __main__ -     Num examples = 8592
08/28/2022 04:15:16 - INFO - __main__ -     Batch size = 128
08/28/2022 04:16:09 - INFO - __main__ -     eval_loss = 0.2902
08/28/2022 04:16:09 - INFO - __main__ -     eval_acc = 0.8927
08/28/2022 04:16:09 - INFO - __main__ -   epoch 23 loss 0.18667
08/28/2022 04:25:40 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 04:25:40 - INFO - __main__ -     Num examples = 8592
08/28/2022 04:25:40 - INFO - __main__ -     Batch size = 128
08/28/2022 04:26:26 - INFO - __main__ -     eval_loss = 0.3022
08/28/2022 04:26:26 - INFO - __main__ -     eval_acc = 0.8786
08/28/2022 04:26:26 - INFO - __main__ -   epoch 24 loss 0.18159
08/28/2022 04:35:58 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 04:35:58 - INFO - __main__ -     Num examples = 8592
08/28/2022 04:35:58 - INFO - __main__ -     Batch size = 128
08/28/2022 04:36:44 - INFO - __main__ -     eval_loss = 0.2855
08/28/2022 04:36:44 - INFO - __main__ -     eval_acc = 0.8912
08/28/2022 04:36:44 - INFO - __main__ -   epoch 25 loss 0.1796
08/28/2022 04:46:23 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 04:46:23 - INFO - __main__ -     Num examples = 8592
08/28/2022 04:46:23 - INFO - __main__ -     Batch size = 128
08/28/2022 04:47:11 - INFO - __main__ -     eval_loss = 0.2918
08/28/2022 04:47:11 - INFO - __main__ -     eval_acc = 0.89
08/28/2022 04:47:12 - INFO - __main__ -   epoch 26 loss 0.17437
08/28/2022 04:56:44 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 04:56:44 - INFO - __main__ -     Num examples = 8592
08/28/2022 04:56:44 - INFO - __main__ -     Batch size = 128
08/28/2022 04:57:36 - INFO - __main__ -     eval_loss = 0.2941
08/28/2022 04:57:36 - INFO - __main__ -     eval_acc = 0.892
08/28/2022 04:57:36 - INFO - __main__ -   epoch 27 loss 0.17166
08/28/2022 05:07:09 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 05:07:09 - INFO - __main__ -     Num examples = 8592
08/28/2022 05:07:09 - INFO - __main__ -     Batch size = 128
08/28/2022 05:08:03 - INFO - __main__ -     eval_loss = 0.2992
08/28/2022 05:08:03 - INFO - __main__ -     eval_acc = 0.8856
08/28/2022 05:08:03 - INFO - __main__ -   epoch 28 loss 0.17112
08/28/2022 05:17:32 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 05:17:32 - INFO - __main__ -     Num examples = 8592
08/28/2022 05:17:32 - INFO - __main__ -     Batch size = 128
08/28/2022 05:18:21 - INFO - __main__ -     eval_loss = 0.2942
08/28/2022 05:18:21 - INFO - __main__ -     eval_acc = 0.8887
08/28/2022 05:18:21 - INFO - __main__ -   epoch 29 loss 0.16763
08/28/2022 05:18:29 - INFO - __main__ -   ***** Running evaluation *****
08/28/2022 05:18:29 - INFO - __main__ -     Num examples = 8592
08/28/2022 05:18:29 - INFO - __main__ -     Batch size = 128
08/28/2022 05:19:16 - INFO - __main__ -   ***** Eval results *****
08/28/2022 05:19:16 - INFO - __main__ -     eval_acc = 0.8977
08/28/2022 05:19:16 - INFO - __main__ -     eval_loss = 0.2975
08/28/2022 05:19:38 - INFO - __main__ -   ***** Running Test *****
08/28/2022 05:19:38 - INFO - __main__ -     Num examples = 21587
08/28/2022 05:19:38 - INFO - __main__ -     Batch size = 128
08/28/2022 05:21:35 - INFO - __main__ -   ***** Test results *****
08/28/2022 05:21:35 - INFO - __main__ -     accuracy = 90.2071
08/28/2022 05:21:35 - INFO - __main__ -     f1_score = 30.0926
08/28/2022 05:21:35 - INFO - __main__ -     precision = 56.1728
08/28/2022 05:21:35 - INFO - __main__ -     recall = 20.551
